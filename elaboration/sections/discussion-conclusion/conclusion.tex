\section{Conclusion}
\label{sec:conclusion}

In this thesis, we compare three different approaches to probabilistic forecasting 
for solar energy generation and compare them on the GEFCom2014 dataset. 
Results show that the QRF and the NNQF model perform similar without 
hyperparameter optimization and that the QRF model improves after the hyperparameter 
optimization. The SQF-RNN model performs better during the summer months than the other two models. 

The QRF and NNQF model are both underdispersed during the night. This can be dealt with by simply forecasting \(0\). 
Nonparametric models are not always the easiest solution. Therefore, it makes sense to sometimes just predict the obvious 
instead of training a complex model.

The discrepancy between the results of the SQF-RNN model and the DeepAR model show that 
nonparametric models can perform better than parametric ones in a context where we do not know the actual probability distribution. 
The pinball loss crowned the QRF model the winner while the energy score marked the SQF-RNN model as winner. 
Different scoring functions emphasize different properties of a forecast -- just because one forecast has a 
better score than another forecast does not mean that it is better than the other in every aspect.

Another point to note is that different models perform differently due to different features being 
prioritized: the QRF and NNQF model both prioritize approximately the same features and therefore 
yield similar results. The SQF-RNN model prioritizes other features and performs in some months better 
and in other months worse than the other two models. A model's performance is highly dependent on the input features.
Therefore, it is important to investigate feature selection in detail and to examine which explaining features promise the best results. 
Future work could investigate feature selection and preprocessing in more detail. 

As discussed in section \ref{sec:discussion}, the SQF-RNN model does not perform as well as expected 
because the competition does not allow the previous time data to be used as an input value. 
Future work could examine how well the SQF-RNN and DeepAR model perform after fixing this issue, 
i.e., enabling \(\SI{24}{\hour}\) ahead forecasts with previous target data. 

Future work could examine how the models behave on other tasks. 
\Textcite{Gasthaus2019} use different datasets for solar energy forecasting with more 
simultaneous time series but fewer predictors. 
The SQF-RNN model performs very well on this dataset; future work could implement the other two models 
on this dataset and compare it with the SQF-RNN and DeepAR model.

Other variants for multivariate time series forecasting have been proposed like a model 
for forecasting multivariate probabilistic time series via conditioned normalizing flows 
by \Textcite{Rasul2020}. We tried out the model on the GEFCom2014 dataset, but it did not yield 
successfull results. The reason for that is probably a similar one as for the SQF-RNN model: 
in the GEFCom2014 dataset, there are too few simultaneous solar plants to forecast. 
Future work could try to compare the model from \Textcite{Rasul2020} with the SQF-RNN and DeepAR model 
on a dataset that works better for these models. 

When we simulate the competition with our models, we see that 
the the QRF model reaches \(15\)th, 
the NNQF model reaches \(16\)th, the SQF-RNN model reaches \(18\)th 
and the DeepAR model reaches \(20\)th place from \(24\) places in the competition. 
The first place in the competition uses Gradient Boosting and \(k\)-Nearest Neighbor techniques 
and the second place uses Quantile Regression Forests and Gradient Boosting Decision Trees. 
The first place also used offsite information while the second place differentiated the variables 
for the accumulated fields in the preprocessing step as well as provided time of day and year data. 
Future work could try to yield better results for QRF and NNQF by preprocessing the data and providing 
external information as predictors. 