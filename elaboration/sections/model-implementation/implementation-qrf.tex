\section{Quantile Regression Forests}
\label{sec:implementation-qrf}

A Python implementation for Quantile Regression Forests can 
be found in the doubt\footnote{\url{https://github.com/saattrupdan/doubt}} package.

First, the data is read from the \texttt{.csv} files. 
Afterwards, the cumulated columns (SSRD, STRD, TSR) are decumulated and then normalized.
Then, the \texttt{QuantileRegressionForest} is wrapped into a pipeline stage in order for 
it to be trained.
After training and prediction, the results are evaluated 
using the pinball loss scoring rule for each time step and zone.

The hyperparameters of Quantile Regression Forests are very similar to the ones 
of conventional Random Forests. We can choose the number of trees in the forest, 
the splitting criterion (mean squared error or mean absolute error), 
the splitting strategy (best split or best random split) 
and the number of features to consider when looking for the best split. 
We can also change the shape of the trees: 
the maximum depth, minimum number of samples required to split a node, the minimum number of samples per leaf and 
the maximum number of leaf nodes can all be adjusted.
The parameters after tuning are shown in Table \ref{table:qrf-hyperparameters}.
\todo{How were the hyperparameters tuned, any interesting/systematic effects?}

\begin{table}[h!]%
    \caption{QRF Hyperparameters}
    \label{table:qrf-hyperparameters}
    \rowcolors{2}{white}{gray!25}
    \centering
    \footnotesize
    \begin{tabular}{ll}
    \toprule \noalign{\smallskip}
    \tableheads Hyperparameter & \tableheads Value \\ 
    \midrule
    Number of trees                             & \(100\)                 \\
    Splitting criterion                         & mean squared error      \\
    Splitting strategy                          & best split              \\
    Maximum number of features for split        & number of features      \\
    Maximum depth                               & any size                \\
    Minimum number of samples required to split & \(2\)                   \\
    Minimum number of samples per leaf          & \(1\)                   \\
    Maximum number of leaves                    & number of points, \(n\) \\
    \bottomrule
    \end{tabular}
\end{table}