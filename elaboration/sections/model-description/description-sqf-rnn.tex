\section{Spline Quantile Function RNNs}
\label{sec:sqf-rnn}

\Textcite{Gasthaus2019} proposed a method for probabilistic forecasting by modeling 
the quantile function with monotonic regression splines. 
The proposed \gls{sqfrnn} model combines the ability to forecast time series 
from recurrent neural networks which was already done by the DeepAR model from \Textcite{Salinas2017}
with the flexibility of being able to 
model the quantile functions with linear splines. 

Let \(x_1, \ldots, x_n \in \R^D\) be the predictor values and 
\(z_1, \ldots, z_n \in \R\) be the target time series. Also, let \(\Theta\) 
be the model parameters, \(\boldsymbol{h}_t\) the network output of 
time step \(t\) and \(\theta_t\) the parameters of the conditional distribution \(\P(z_t | \theta_t)\).
The model works as follows:
Compute the network output \(\boldsymbol{h}_t = h(\boldsymbol{h}_{t-1}, z_{t-1}, x_t, \Theta)\) 
as well as the parameters \(\theta_t = \theta(\boldsymbol{h}_t, \Theta)\) for the distribution
\(\P(z_t | \theta_t)\). \(h(\cdot)\) is a multi-layer RNN with 
LSTM cells and \(\theta(\cdot)\) is a projection layer. 
The quantiles are then used to calculate the loss and train the model parameters \(\Theta\).
The process is illustrated in Figure \ref{fig:deepar-training}.

\begin{figure}[h]%
    \centering
    \input{plots/deepar_training}
    \caption{DeepAR Training}%
    \label{fig:deepar-training}%
\end{figure}

For the prediction step, the target time series are not known. 
The known history of the time series \(z_1, \ldots, z_{t_0}\) is fed into the 
model and for \(t > t_0\), samples \(\tilde{z}_t \sim \P(z_t | \theta_t)\) 
are generated and fed back into the model for the next time step.
The process is illustrated in Figure \ref{fig:deepar-predicting}.

\begin{figure}[h]%
    \centering
    \input{plots/deepar_predicting}
    \caption{DeepAR Predicting}%
    \label{fig:deepar-predicting}%
\end{figure}

While the DeepAR model is trained by maximizing the likelihood function, 
the SQF-RNN model is trained by minimizing the CRPS (see \ref{ch:crps}) 
which can be computed effectively for spline-based quantile functions.

A linear spline with \(L\) pieces is of the form 
\[ s(x; \gamma, b, d) = \gamma + \sum_{l=0}^L b_l (x - d_l)_+, 
\quad b, d \in \R^{L+1}. \]
Since we want a monotone spline, we need to create constraints for \(b_l\) and \(d_l\).
We want \(d_l < d_{l+1}\) for ordered knot positions. To achieve this 
in the neural network, we set \(d_0 = 0\) and \(d_l = \sum_{j=1}^l \delta_j\), 
where \(\delta_j \geq 0\) and \(\sum_{j=1}^L \delta_j = 1\) since the domain 
of the quantile function is \([0, 1]\). 
We also want monotonicity: the slope \(m_l\) between two knots is given by 
\(m_l = \sum_{j=0}^l b_j\). We need to make sure that \(m_l \geq 0 \forall l\).
If we set \(b_l = \beta_l - \beta_{l-1}\) and \(b_0 = \beta_0\) with \(\beta_l \geq 0 \forall l\), 
we get \(m_l = \sum_{j=0}^l b_j = \beta_l \geq 0\).
We can therefore model our spline with the parameter 
\(\theta = (\gamma, \beta, \delta)\), \(\gamma \in \R, \beta \in [0,\infty)^{L}, 
\delta \in \set{ \delta \in [0,1]^L: \sum_{j=1}^L \delta_j = 1 }\).