{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/pavelzw/GEFCom14-S-comparison/blob/main/gefcom14-s-nnqf.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/pavelzw/GEFCom14-S-comparison/blob/main/gefcom14-s-nnqf.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
    "    View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://minhaskamal.github.io/DownGit/#/home?url=https://github.com/pavelzw/GEFCom14-S-comparison/blob/main/gefcom14-s-deepar.ipynb&fileName=gefcom14-s-nnqf\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "!echo \"Downloading GEFCom14-S...\"\n",
    "!rm -R data > /dev/null\n",
    "!wget -O gefcom14.zip https://www.dropbox.com/s/pqenrr2mcvl0hk9/GEFCom2014.zip?dl=0\n",
    "!unzip gefcom14 > /dev/null\n",
    "!rm gefcom14.zip > /dev/null\n",
    "!unzip GEFCom2014\\ Data/GEFCom2014-S_V2.zip > /dev/null\n",
    "!rm -R GEFCom2014\\ Data > /dev/null\n",
    "!mv Solar data > /dev/null\n",
    "!echo \"------------------------------\"\n",
    "!echo \"Downloaded GEFCom14-S in data/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "task = 2\n",
    "# only use surface solar radiation (169), surface thermal radiation (175) and top net solar radiation (178)\n",
    "predictors = pd.read_csv(f'data/Task {task}/predictors{task}.csv', parse_dates=['TIMESTAMP'])\\\n",
    "    [['ZONEID', 'TIMESTAMP', 'VAR169', 'VAR175', 'VAR178']].set_index('TIMESTAMP')\n",
    "train = pd.read_csv(f'data/Task {task}/train{task}.csv', parse_dates=['TIMESTAMP']).set_index('TIMESTAMP')\n",
    "benchmark = pd.read_csv(f\"data/Task {task-1}/benchmark{'0' + str(task-1) if task-1 < 10 else task}.csv\",\n",
    "                        parse_dates=['TIMESTAMP']).set_index('TIMESTAMP')\n",
    "\n",
    "solar_plants = [train[train['ZONEID'] == i][['POWER']].rename({'POWER': f'ZONEID {i}'}, axis='columns')\n",
    "                for i in [1,2,3]]\n",
    "train_data = pd.concat(solar_plants, axis=1)\n",
    "\n",
    "predictors_categories = [predictors[predictors['ZONEID'] == i][['VAR169', 'VAR175', 'VAR178']]\n",
    "                             .rename({'VAR169': f'SURFACE SOLAR RADIATION {i}',\n",
    "                                      'VAR175': f'SURFACE THERMAL RADIATION {i}',\n",
    "                                      'VAR178': f'TOP NET SOLAR RADIATION {i}'}, axis='columns')\n",
    "                         for i in [1,2,3]]\n",
    "predictor_data = pd.concat(predictors_categories, axis=1)[:'2013-05-01 00:00']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "predictor1 = predictor_data[['SURFACE SOLAR RADIATION 1', 'SURFACE THERMAL RADIATION 1', 'TOP NET SOLAR RADIATION 1']]\n",
    "\n",
    "train_data1 = train_data[['ZONEID 1']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "x_input_df = predictor1\n",
    "x_input = np.array(x_input_df)\n",
    "y_output = np.array(train_data1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "minkowski_dist = 2\n",
    "x_neighbors = NearestNeighbors(n_neighbors=50, algorithm='auto', p=minkowski_dist).fit(x_input)\n",
    "dist, indx = x_neighbors.kneighbors(x_input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "y_neighbors = y_output[indx[0, :]].T\n",
    "for i in range(1, np.size(indx, 0)):\n",
    "    values_to_add = y_output[indx[i, :]].T\n",
    "    y_neighbors = np.vstack([y_neighbors, values_to_add])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                         0.01      0.02      0.03      0.04      0.05  \\\nTIMESTAMP                                                               \n2012-04-01 01:00:00  0.325074  0.486365  0.505211  0.517995  0.532077   \n2012-04-01 02:00:00  0.085936  0.099756  0.192001  0.287582  0.366721   \n2012-04-01 03:00:00  0.098879  0.197759  0.270035  0.341179  0.347247   \n2012-04-01 04:00:00  0.071335  0.142542  0.172504  0.200710  0.204397   \n2012-04-01 05:00:00  0.026924  0.030003  0.034708  0.039482  0.040679   \n...                       ...       ...       ...       ...       ...   \n2013-04-30 20:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n2013-04-30 21:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n2013-04-30 22:00:00  0.000000  0.000000  0.000000  0.000000  0.000288   \n2013-04-30 23:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n2013-05-01 00:00:00  0.000000  0.000000  0.000090  0.000185  0.000308   \n\n                         0.06      0.07      0.08      0.09       0.1  ...  \\\nTIMESTAMP                                                              ...   \n2012-04-01 01:00:00  0.546274  0.562346  0.578679  0.601452  0.625481  ...   \n2012-04-01 02:00:00  0.444399  0.471193  0.490887  0.495180  0.496468  ...   \n2012-04-01 03:00:00  0.347529  0.375238  0.406774  0.412869  0.414000  ...   \n2012-04-01 04:00:00  0.205905  0.206696  0.207387  0.212651  0.218808  ...   \n2012-04-01 05:00:00  0.041559  0.042687  0.043849  0.044564  0.045192  ...   \n...                       ...       ...       ...       ...       ...  ...   \n2013-04-30 20:00:00  0.000000  0.000000  0.000000  0.000000  0.000000  ...   \n2013-04-30 21:00:00  0.000000  0.000000  0.000000  0.000000  0.000000  ...   \n2013-04-30 22:00:00  0.000603  0.000751  0.000877  0.001292  0.001763  ...   \n2013-04-30 23:00:00  0.000000  0.000055  0.000118  0.000338  0.000590  ...   \n2013-05-01 00:00:00  0.000433  0.001055  0.001746  0.001938  0.002032  ...   \n\n                          0.9      0.91      0.92      0.93      0.94  \\\nTIMESTAMP                                                               \n2012-04-01 01:00:00  0.841795  0.842737  0.843715  0.844878  0.846878   \n2012-04-01 02:00:00  0.821442  0.824112  0.826797  0.829562  0.832760   \n2012-04-01 03:00:00  0.758160  0.758569  0.758915  0.758947  0.759597   \n2012-04-01 04:00:00  0.615276  0.616312  0.617308  0.618093  0.619305   \n2012-04-01 05:00:00  0.503051  0.517688  0.531741  0.542797  0.552677   \n...                       ...       ...       ...       ...       ...   \n2013-04-30 20:00:00  0.211071  0.214431  0.245367  0.417621  0.569544   \n2013-04-30 21:00:00  0.542821  0.556955  0.569797  0.576017  0.582497   \n2013-04-30 22:00:00  0.581615  0.582306  0.584136  0.591800  0.599837   \n2013-04-30 23:00:00  0.530301  0.535547  0.540838  0.546367  0.553118   \n2013-05-01 00:00:00  0.580128  0.598660  0.614408  0.615884  0.618814   \n\n                         0.95      0.96      0.97      0.98      0.99  \nTIMESTAMP                                                              \n2012-04-01 01:00:00  0.854888  0.863836  0.883342  0.902090  0.903032  \n2012-04-01 02:00:00  0.839074  0.845972  0.859447  0.873092  0.890745  \n2012-04-01 03:00:00  0.764686  0.770987  0.790933  0.810664  0.825364  \n2012-04-01 04:00:00  0.623577  0.628623  0.642381  0.657579  0.706642  \n2012-04-01 05:00:00  0.554122  0.558800  0.599853  0.639619  0.649137  \n...                       ...       ...       ...       ...       ...  \n2013-04-30 20:00:00  0.575763  0.582156  0.590512  0.599101  0.613204  \n2013-04-30 21:00:00  0.590853  0.600308  0.622138  0.646018  0.718073  \n2013-04-30 22:00:00  0.610548  0.621292  0.632412  0.646018  0.718073  \n2013-04-30 23:00:00  0.568635  0.584385  0.602760  0.620838  0.631958  \n2013-05-01 00:00:00  0.632163  0.645123  0.653698  0.662164  0.668069  \n\n[9480 rows x 99 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0.01</th>\n      <th>0.02</th>\n      <th>0.03</th>\n      <th>0.04</th>\n      <th>0.05</th>\n      <th>0.06</th>\n      <th>0.07</th>\n      <th>0.08</th>\n      <th>0.09</th>\n      <th>0.1</th>\n      <th>...</th>\n      <th>0.9</th>\n      <th>0.91</th>\n      <th>0.92</th>\n      <th>0.93</th>\n      <th>0.94</th>\n      <th>0.95</th>\n      <th>0.96</th>\n      <th>0.97</th>\n      <th>0.98</th>\n      <th>0.99</th>\n    </tr>\n    <tr>\n      <th>TIMESTAMP</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2012-04-01 01:00:00</th>\n      <td>0.325074</td>\n      <td>0.486365</td>\n      <td>0.505211</td>\n      <td>0.517995</td>\n      <td>0.532077</td>\n      <td>0.546274</td>\n      <td>0.562346</td>\n      <td>0.578679</td>\n      <td>0.601452</td>\n      <td>0.625481</td>\n      <td>...</td>\n      <td>0.841795</td>\n      <td>0.842737</td>\n      <td>0.843715</td>\n      <td>0.844878</td>\n      <td>0.846878</td>\n      <td>0.854888</td>\n      <td>0.863836</td>\n      <td>0.883342</td>\n      <td>0.902090</td>\n      <td>0.903032</td>\n    </tr>\n    <tr>\n      <th>2012-04-01 02:00:00</th>\n      <td>0.085936</td>\n      <td>0.099756</td>\n      <td>0.192001</td>\n      <td>0.287582</td>\n      <td>0.366721</td>\n      <td>0.444399</td>\n      <td>0.471193</td>\n      <td>0.490887</td>\n      <td>0.495180</td>\n      <td>0.496468</td>\n      <td>...</td>\n      <td>0.821442</td>\n      <td>0.824112</td>\n      <td>0.826797</td>\n      <td>0.829562</td>\n      <td>0.832760</td>\n      <td>0.839074</td>\n      <td>0.845972</td>\n      <td>0.859447</td>\n      <td>0.873092</td>\n      <td>0.890745</td>\n    </tr>\n    <tr>\n      <th>2012-04-01 03:00:00</th>\n      <td>0.098879</td>\n      <td>0.197759</td>\n      <td>0.270035</td>\n      <td>0.341179</td>\n      <td>0.347247</td>\n      <td>0.347529</td>\n      <td>0.375238</td>\n      <td>0.406774</td>\n      <td>0.412869</td>\n      <td>0.414000</td>\n      <td>...</td>\n      <td>0.758160</td>\n      <td>0.758569</td>\n      <td>0.758915</td>\n      <td>0.758947</td>\n      <td>0.759597</td>\n      <td>0.764686</td>\n      <td>0.770987</td>\n      <td>0.790933</td>\n      <td>0.810664</td>\n      <td>0.825364</td>\n    </tr>\n    <tr>\n      <th>2012-04-01 04:00:00</th>\n      <td>0.071335</td>\n      <td>0.142542</td>\n      <td>0.172504</td>\n      <td>0.200710</td>\n      <td>0.204397</td>\n      <td>0.205905</td>\n      <td>0.206696</td>\n      <td>0.207387</td>\n      <td>0.212651</td>\n      <td>0.218808</td>\n      <td>...</td>\n      <td>0.615276</td>\n      <td>0.616312</td>\n      <td>0.617308</td>\n      <td>0.618093</td>\n      <td>0.619305</td>\n      <td>0.623577</td>\n      <td>0.628623</td>\n      <td>0.642381</td>\n      <td>0.657579</td>\n      <td>0.706642</td>\n    </tr>\n    <tr>\n      <th>2012-04-01 05:00:00</th>\n      <td>0.026924</td>\n      <td>0.030003</td>\n      <td>0.034708</td>\n      <td>0.039482</td>\n      <td>0.040679</td>\n      <td>0.041559</td>\n      <td>0.042687</td>\n      <td>0.043849</td>\n      <td>0.044564</td>\n      <td>0.045192</td>\n      <td>...</td>\n      <td>0.503051</td>\n      <td>0.517688</td>\n      <td>0.531741</td>\n      <td>0.542797</td>\n      <td>0.552677</td>\n      <td>0.554122</td>\n      <td>0.558800</td>\n      <td>0.599853</td>\n      <td>0.639619</td>\n      <td>0.649137</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2013-04-30 20:00:00</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.211071</td>\n      <td>0.214431</td>\n      <td>0.245367</td>\n      <td>0.417621</td>\n      <td>0.569544</td>\n      <td>0.575763</td>\n      <td>0.582156</td>\n      <td>0.590512</td>\n      <td>0.599101</td>\n      <td>0.613204</td>\n    </tr>\n    <tr>\n      <th>2013-04-30 21:00:00</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.542821</td>\n      <td>0.556955</td>\n      <td>0.569797</td>\n      <td>0.576017</td>\n      <td>0.582497</td>\n      <td>0.590853</td>\n      <td>0.600308</td>\n      <td>0.622138</td>\n      <td>0.646018</td>\n      <td>0.718073</td>\n    </tr>\n    <tr>\n      <th>2013-04-30 22:00:00</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000288</td>\n      <td>0.000603</td>\n      <td>0.000751</td>\n      <td>0.000877</td>\n      <td>0.001292</td>\n      <td>0.001763</td>\n      <td>...</td>\n      <td>0.581615</td>\n      <td>0.582306</td>\n      <td>0.584136</td>\n      <td>0.591800</td>\n      <td>0.599837</td>\n      <td>0.610548</td>\n      <td>0.621292</td>\n      <td>0.632412</td>\n      <td>0.646018</td>\n      <td>0.718073</td>\n    </tr>\n    <tr>\n      <th>2013-04-30 23:00:00</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000055</td>\n      <td>0.000118</td>\n      <td>0.000338</td>\n      <td>0.000590</td>\n      <td>...</td>\n      <td>0.530301</td>\n      <td>0.535547</td>\n      <td>0.540838</td>\n      <td>0.546367</td>\n      <td>0.553118</td>\n      <td>0.568635</td>\n      <td>0.584385</td>\n      <td>0.602760</td>\n      <td>0.620838</td>\n      <td>0.631958</td>\n    </tr>\n    <tr>\n      <th>2013-05-01 00:00:00</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000090</td>\n      <td>0.000185</td>\n      <td>0.000308</td>\n      <td>0.000433</td>\n      <td>0.001055</td>\n      <td>0.001746</td>\n      <td>0.001938</td>\n      <td>0.002032</td>\n      <td>...</td>\n      <td>0.580128</td>\n      <td>0.598660</td>\n      <td>0.614408</td>\n      <td>0.615884</td>\n      <td>0.618814</td>\n      <td>0.632163</td>\n      <td>0.645123</td>\n      <td>0.653698</td>\n      <td>0.662164</td>\n      <td>0.668069</td>\n    </tr>\n  </tbody>\n</table>\n<p>9480 rows × 99 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yq_output = np.quantile(y_neighbors, q=[p / 100 for p in range(1, 100)], axis=1).T\n",
    "yq_output_df = pd.DataFrame(yq_output, index=x_input_df.index)\\\n",
    "    .rename(columns={p: str((p+1)/100) for p in range(99)})\n",
    "yq_output_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the linear regression model (ANN10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare data for regression model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "             0         1         2\n0     0.070457  0.010104  0.057922\n1     0.152360  0.047458  0.142628\n2     0.227996  0.084522  0.224650\n3     0.285150  0.121753  0.290287\n4     0.322960  0.161768  0.338952\n...        ...       ...       ...\n9475  0.220287  0.683490  0.256298\n9476  0.220471  0.720201  0.256733\n9477  0.226896  0.758322  0.267201\n9478  0.244268  0.796864  0.291180\n9479  0.282444  0.832235  0.334318\n\n[9480 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.070457</td>\n      <td>0.010104</td>\n      <td>0.057922</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.152360</td>\n      <td>0.047458</td>\n      <td>0.142628</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.227996</td>\n      <td>0.084522</td>\n      <td>0.224650</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.285150</td>\n      <td>0.121753</td>\n      <td>0.290287</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.322960</td>\n      <td>0.161768</td>\n      <td>0.338952</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9475</th>\n      <td>0.220287</td>\n      <td>0.683490</td>\n      <td>0.256298</td>\n    </tr>\n    <tr>\n      <th>9476</th>\n      <td>0.220471</td>\n      <td>0.720201</td>\n      <td>0.256733</td>\n    </tr>\n    <tr>\n      <th>9477</th>\n      <td>0.226896</td>\n      <td>0.758322</td>\n      <td>0.267201</td>\n    </tr>\n    <tr>\n      <th>9478</th>\n      <td>0.244268</td>\n      <td>0.796864</td>\n      <td>0.291180</td>\n    </tr>\n    <tr>\n      <th>9479</th>\n      <td>0.282444</td>\n      <td>0.832235</td>\n      <td>0.334318</td>\n    </tr>\n  </tbody>\n</table>\n<p>9480 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# normalize predictor values\n",
    "x = predictor1.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "scaled = min_max_scaler.fit_transform(x)\n",
    "predictor1 = pd.DataFrame(scaled)\n",
    "predictor1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "             0         1         2         0         1         2         0  \\\n23    0.450364  0.837689  0.506044  0.406165  0.796552  0.454506  0.376154   \n24    0.045105  0.013434  0.039247  0.450364  0.837689  0.506044  0.406165   \n25    0.092515  0.053876  0.098001  0.045105  0.013434  0.039247  0.450364   \n26    0.145630  0.095325  0.160508  0.092515  0.053876  0.098001  0.045105   \n27    0.198880  0.135820  0.222171  0.145630  0.095325  0.160508  0.092515   \n...        ...       ...       ...       ...       ...       ...       ...   \n9475  0.220287  0.683490  0.256298  0.220287  0.646925  0.256298  0.220287   \n9476  0.220471  0.720201  0.256733  0.220287  0.683490  0.256298  0.220287   \n9477  0.226896  0.758322  0.267201  0.220471  0.720201  0.256733  0.220287   \n9478  0.244268  0.796864  0.291180  0.226896  0.758322  0.267201  0.220471   \n9479  0.282444  0.832235  0.334318  0.244268  0.796864  0.291180  0.226896   \n\n             1         2         0  ...         2         0         1  \\\n23    0.758559  0.417812  0.360530  ...  0.290287  0.227996  0.084522   \n24    0.796552  0.454506  0.376154  ...  0.338952  0.285150  0.121753   \n25    0.837689  0.506044  0.406165  ...  0.368936  0.322960  0.161768   \n26    0.013434  0.039247  0.450364  ...  0.388876  0.342790  0.200918   \n27    0.053876  0.098001  0.045105  ...  0.394023  0.356316  0.238150   \n...        ...       ...       ...  ...       ...       ...       ...   \n9475  0.613121  0.256298  0.220287  ...  0.387337  0.329628  0.833101   \n9476  0.646925  0.256298  0.220287  ...  0.017545  0.349089  0.872224   \n9477  0.683490  0.256298  0.220287  ...  0.063724  0.020428  0.014910   \n9478  0.720201  0.256733  0.220287  ...  0.119693  0.056263  0.054627   \n9479  0.758322  0.267201  0.220471  ...  0.175003  0.103475  0.093193   \n\n             2         0         1         2         0         1         2  \n23    0.224650  0.152360  0.047458  0.142628  0.070457  0.010104  0.057922  \n24    0.290287  0.227996  0.084522  0.224650  0.152360  0.047458  0.142628  \n25    0.338952  0.285150  0.121753  0.290287  0.227996  0.084522  0.224650  \n26    0.368936  0.322960  0.161768  0.338952  0.285150  0.121753  0.290287  \n27    0.388876  0.342790  0.200918  0.368936  0.322960  0.161768  0.338952  \n...        ...       ...       ...       ...       ...       ...       ...  \n9475  0.358668  0.309107  0.795727  0.332274  0.305069  0.757640  0.324127  \n9476  0.387337  0.329628  0.833101  0.358668  0.309107  0.795727  0.332274  \n9477  0.017545  0.349089  0.872224  0.387337  0.329628  0.833101  0.358668  \n9478  0.063724  0.020428  0.014910  0.017545  0.349089  0.872224  0.387337  \n9479  0.119693  0.056263  0.054627  0.063724  0.020428  0.014910  0.017545  \n\n[9457 rows x 72 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>0</th>\n      <th>...</th>\n      <th>2</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23</th>\n      <td>0.450364</td>\n      <td>0.837689</td>\n      <td>0.506044</td>\n      <td>0.406165</td>\n      <td>0.796552</td>\n      <td>0.454506</td>\n      <td>0.376154</td>\n      <td>0.758559</td>\n      <td>0.417812</td>\n      <td>0.360530</td>\n      <td>...</td>\n      <td>0.290287</td>\n      <td>0.227996</td>\n      <td>0.084522</td>\n      <td>0.224650</td>\n      <td>0.152360</td>\n      <td>0.047458</td>\n      <td>0.142628</td>\n      <td>0.070457</td>\n      <td>0.010104</td>\n      <td>0.057922</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.045105</td>\n      <td>0.013434</td>\n      <td>0.039247</td>\n      <td>0.450364</td>\n      <td>0.837689</td>\n      <td>0.506044</td>\n      <td>0.406165</td>\n      <td>0.796552</td>\n      <td>0.454506</td>\n      <td>0.376154</td>\n      <td>...</td>\n      <td>0.338952</td>\n      <td>0.285150</td>\n      <td>0.121753</td>\n      <td>0.290287</td>\n      <td>0.227996</td>\n      <td>0.084522</td>\n      <td>0.224650</td>\n      <td>0.152360</td>\n      <td>0.047458</td>\n      <td>0.142628</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.092515</td>\n      <td>0.053876</td>\n      <td>0.098001</td>\n      <td>0.045105</td>\n      <td>0.013434</td>\n      <td>0.039247</td>\n      <td>0.450364</td>\n      <td>0.837689</td>\n      <td>0.506044</td>\n      <td>0.406165</td>\n      <td>...</td>\n      <td>0.368936</td>\n      <td>0.322960</td>\n      <td>0.161768</td>\n      <td>0.338952</td>\n      <td>0.285150</td>\n      <td>0.121753</td>\n      <td>0.290287</td>\n      <td>0.227996</td>\n      <td>0.084522</td>\n      <td>0.224650</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.145630</td>\n      <td>0.095325</td>\n      <td>0.160508</td>\n      <td>0.092515</td>\n      <td>0.053876</td>\n      <td>0.098001</td>\n      <td>0.045105</td>\n      <td>0.013434</td>\n      <td>0.039247</td>\n      <td>0.450364</td>\n      <td>...</td>\n      <td>0.388876</td>\n      <td>0.342790</td>\n      <td>0.200918</td>\n      <td>0.368936</td>\n      <td>0.322960</td>\n      <td>0.161768</td>\n      <td>0.338952</td>\n      <td>0.285150</td>\n      <td>0.121753</td>\n      <td>0.290287</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.198880</td>\n      <td>0.135820</td>\n      <td>0.222171</td>\n      <td>0.145630</td>\n      <td>0.095325</td>\n      <td>0.160508</td>\n      <td>0.092515</td>\n      <td>0.053876</td>\n      <td>0.098001</td>\n      <td>0.045105</td>\n      <td>...</td>\n      <td>0.394023</td>\n      <td>0.356316</td>\n      <td>0.238150</td>\n      <td>0.388876</td>\n      <td>0.342790</td>\n      <td>0.200918</td>\n      <td>0.368936</td>\n      <td>0.322960</td>\n      <td>0.161768</td>\n      <td>0.338952</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9475</th>\n      <td>0.220287</td>\n      <td>0.683490</td>\n      <td>0.256298</td>\n      <td>0.220287</td>\n      <td>0.646925</td>\n      <td>0.256298</td>\n      <td>0.220287</td>\n      <td>0.613121</td>\n      <td>0.256298</td>\n      <td>0.220287</td>\n      <td>...</td>\n      <td>0.387337</td>\n      <td>0.329628</td>\n      <td>0.833101</td>\n      <td>0.358668</td>\n      <td>0.309107</td>\n      <td>0.795727</td>\n      <td>0.332274</td>\n      <td>0.305069</td>\n      <td>0.757640</td>\n      <td>0.324127</td>\n    </tr>\n    <tr>\n      <th>9476</th>\n      <td>0.220471</td>\n      <td>0.720201</td>\n      <td>0.256733</td>\n      <td>0.220287</td>\n      <td>0.683490</td>\n      <td>0.256298</td>\n      <td>0.220287</td>\n      <td>0.646925</td>\n      <td>0.256298</td>\n      <td>0.220287</td>\n      <td>...</td>\n      <td>0.017545</td>\n      <td>0.349089</td>\n      <td>0.872224</td>\n      <td>0.387337</td>\n      <td>0.329628</td>\n      <td>0.833101</td>\n      <td>0.358668</td>\n      <td>0.309107</td>\n      <td>0.795727</td>\n      <td>0.332274</td>\n    </tr>\n    <tr>\n      <th>9477</th>\n      <td>0.226896</td>\n      <td>0.758322</td>\n      <td>0.267201</td>\n      <td>0.220471</td>\n      <td>0.720201</td>\n      <td>0.256733</td>\n      <td>0.220287</td>\n      <td>0.683490</td>\n      <td>0.256298</td>\n      <td>0.220287</td>\n      <td>...</td>\n      <td>0.063724</td>\n      <td>0.020428</td>\n      <td>0.014910</td>\n      <td>0.017545</td>\n      <td>0.349089</td>\n      <td>0.872224</td>\n      <td>0.387337</td>\n      <td>0.329628</td>\n      <td>0.833101</td>\n      <td>0.358668</td>\n    </tr>\n    <tr>\n      <th>9478</th>\n      <td>0.244268</td>\n      <td>0.796864</td>\n      <td>0.291180</td>\n      <td>0.226896</td>\n      <td>0.758322</td>\n      <td>0.267201</td>\n      <td>0.220471</td>\n      <td>0.720201</td>\n      <td>0.256733</td>\n      <td>0.220287</td>\n      <td>...</td>\n      <td>0.119693</td>\n      <td>0.056263</td>\n      <td>0.054627</td>\n      <td>0.063724</td>\n      <td>0.020428</td>\n      <td>0.014910</td>\n      <td>0.017545</td>\n      <td>0.349089</td>\n      <td>0.872224</td>\n      <td>0.387337</td>\n    </tr>\n    <tr>\n      <th>9479</th>\n      <td>0.282444</td>\n      <td>0.832235</td>\n      <td>0.334318</td>\n      <td>0.244268</td>\n      <td>0.796864</td>\n      <td>0.291180</td>\n      <td>0.226896</td>\n      <td>0.758322</td>\n      <td>0.267201</td>\n      <td>0.220471</td>\n      <td>...</td>\n      <td>0.175003</td>\n      <td>0.103475</td>\n      <td>0.093193</td>\n      <td>0.119693</td>\n      <td>0.056263</td>\n      <td>0.054627</td>\n      <td>0.063724</td>\n      <td>0.020428</td>\n      <td>0.014910</td>\n      <td>0.017545</td>\n    </tr>\n  </tbody>\n</table>\n<p>9457 rows × 72 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = 24\n",
    "h1 = 24\n",
    "\n",
    "data = predictor1\n",
    "x_pieces = []\n",
    "for i in range(h1):\n",
    "    piece = data.drop(range(i)).reset_index().drop('index', axis=1)\n",
    "    x_pieces.insert(0, piece)\n",
    "\n",
    "x = pd.concat(x_pieces, axis=1)\n",
    "x.index = x.index.map(lambda x: x + h1 - 1)\n",
    "x = x[:-h+1]\n",
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:58<00:00,  1.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "         0.01      0.02      0.03      0.04      0.05      0.06      0.07  \\\n0    0.167383  0.213278  0.237100  0.302447  0.323161  0.287237  0.347237   \n1    0.234482  0.280707  0.268995  0.353297  0.352449  0.365478  0.380751   \n2    0.239233  0.248735  0.251229  0.316796  0.325106  0.300717  0.337155   \n3    0.164125  0.197023  0.182277  0.214218  0.229559  0.214144  0.252581   \n4    0.055321  0.080528  0.076193  0.134463  0.091388  0.143478  0.136330   \n..        ...       ...       ...       ...       ...       ...       ...   \n715  0.018350  0.004713 -0.023331 -0.022603 -0.022901 -0.011089 -0.028234   \n716  0.011441  0.004713 -0.041438  0.018533  0.005430 -0.014529 -0.005863   \n717  0.030472  0.004713 -0.001376  0.034183 -0.016034  0.002141 -0.017697   \n718  0.021852  0.004713 -0.033894  0.000751  0.044730 -0.070975 -0.003298   \n719  0.114490  0.004713 -0.063506  0.053047  0.032656 -0.023615  0.042644   \n\n         0.08      0.09       0.1  ...       0.9      0.91      0.92  \\\n0    0.351798  0.392957  0.337612  ...  0.807347  0.846042  0.787106   \n1    0.394960  0.422626  0.413334  ...  0.803782  0.828693  0.820339   \n2    0.381028  0.395107  0.380344  ...  0.747710  0.771480  0.749459   \n3    0.282923  0.336122  0.326846  ...  0.654380  0.666673  0.719377   \n4    0.120015  0.201728  0.189246  ...  0.535942  0.536634  0.561117   \n..        ...       ...       ...  ...       ...       ...       ...   \n715 -0.036396 -0.013093  0.020701  ...  0.214661  0.249407  0.231498   \n716 -0.098098 -0.008055 -0.011548  ...  0.299445  0.297547  0.226758   \n717 -0.051888 -0.009368 -0.036219  ...  0.385998  0.392216  0.385719   \n718 -0.035085 -0.020736  0.016223  ...  0.510391  0.536718  0.510260   \n719 -0.006239 -0.028536 -0.000599  ...  0.612297  0.715656  0.608314   \n\n         0.93      0.94      0.95      0.96      0.97      0.98      0.99  \n0    0.832573  0.852729  0.882909  0.808327  0.866491  0.904169  0.825671  \n1    0.851787  0.911148  0.878614  0.831767  0.866993  0.886908  0.825671  \n2    0.793470  0.862186  0.835834  0.803109  0.824687  0.822201  0.813143  \n3    0.709829  0.781214  0.727541  0.732931  0.728029  0.763533  0.707076  \n4    0.611603  0.656572  0.661266  0.631701  0.569262  0.669207  0.652675  \n..        ...       ...       ...       ...       ...       ...       ...  \n715  0.318176  0.337180  0.343603  0.351199  0.374901  0.353494  0.396412  \n716  0.404083  0.430365  0.380261  0.401462  0.412199  0.441784  0.415209  \n717  0.522726  0.523380  0.531310  0.561529  0.527206  0.538442  0.534621  \n718  0.648294  0.554280  0.629662  0.551755  0.647816  0.610791  0.630213  \n719  0.695267  0.617968  0.705954  0.613238  0.686861  0.733623  0.683919  \n\n[720 rows x 99 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0.01</th>\n      <th>0.02</th>\n      <th>0.03</th>\n      <th>0.04</th>\n      <th>0.05</th>\n      <th>0.06</th>\n      <th>0.07</th>\n      <th>0.08</th>\n      <th>0.09</th>\n      <th>0.1</th>\n      <th>...</th>\n      <th>0.9</th>\n      <th>0.91</th>\n      <th>0.92</th>\n      <th>0.93</th>\n      <th>0.94</th>\n      <th>0.95</th>\n      <th>0.96</th>\n      <th>0.97</th>\n      <th>0.98</th>\n      <th>0.99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.167383</td>\n      <td>0.213278</td>\n      <td>0.237100</td>\n      <td>0.302447</td>\n      <td>0.323161</td>\n      <td>0.287237</td>\n      <td>0.347237</td>\n      <td>0.351798</td>\n      <td>0.392957</td>\n      <td>0.337612</td>\n      <td>...</td>\n      <td>0.807347</td>\n      <td>0.846042</td>\n      <td>0.787106</td>\n      <td>0.832573</td>\n      <td>0.852729</td>\n      <td>0.882909</td>\n      <td>0.808327</td>\n      <td>0.866491</td>\n      <td>0.904169</td>\n      <td>0.825671</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.234482</td>\n      <td>0.280707</td>\n      <td>0.268995</td>\n      <td>0.353297</td>\n      <td>0.352449</td>\n      <td>0.365478</td>\n      <td>0.380751</td>\n      <td>0.394960</td>\n      <td>0.422626</td>\n      <td>0.413334</td>\n      <td>...</td>\n      <td>0.803782</td>\n      <td>0.828693</td>\n      <td>0.820339</td>\n      <td>0.851787</td>\n      <td>0.911148</td>\n      <td>0.878614</td>\n      <td>0.831767</td>\n      <td>0.866993</td>\n      <td>0.886908</td>\n      <td>0.825671</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.239233</td>\n      <td>0.248735</td>\n      <td>0.251229</td>\n      <td>0.316796</td>\n      <td>0.325106</td>\n      <td>0.300717</td>\n      <td>0.337155</td>\n      <td>0.381028</td>\n      <td>0.395107</td>\n      <td>0.380344</td>\n      <td>...</td>\n      <td>0.747710</td>\n      <td>0.771480</td>\n      <td>0.749459</td>\n      <td>0.793470</td>\n      <td>0.862186</td>\n      <td>0.835834</td>\n      <td>0.803109</td>\n      <td>0.824687</td>\n      <td>0.822201</td>\n      <td>0.813143</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.164125</td>\n      <td>0.197023</td>\n      <td>0.182277</td>\n      <td>0.214218</td>\n      <td>0.229559</td>\n      <td>0.214144</td>\n      <td>0.252581</td>\n      <td>0.282923</td>\n      <td>0.336122</td>\n      <td>0.326846</td>\n      <td>...</td>\n      <td>0.654380</td>\n      <td>0.666673</td>\n      <td>0.719377</td>\n      <td>0.709829</td>\n      <td>0.781214</td>\n      <td>0.727541</td>\n      <td>0.732931</td>\n      <td>0.728029</td>\n      <td>0.763533</td>\n      <td>0.707076</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.055321</td>\n      <td>0.080528</td>\n      <td>0.076193</td>\n      <td>0.134463</td>\n      <td>0.091388</td>\n      <td>0.143478</td>\n      <td>0.136330</td>\n      <td>0.120015</td>\n      <td>0.201728</td>\n      <td>0.189246</td>\n      <td>...</td>\n      <td>0.535942</td>\n      <td>0.536634</td>\n      <td>0.561117</td>\n      <td>0.611603</td>\n      <td>0.656572</td>\n      <td>0.661266</td>\n      <td>0.631701</td>\n      <td>0.569262</td>\n      <td>0.669207</td>\n      <td>0.652675</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>715</th>\n      <td>0.018350</td>\n      <td>0.004713</td>\n      <td>-0.023331</td>\n      <td>-0.022603</td>\n      <td>-0.022901</td>\n      <td>-0.011089</td>\n      <td>-0.028234</td>\n      <td>-0.036396</td>\n      <td>-0.013093</td>\n      <td>0.020701</td>\n      <td>...</td>\n      <td>0.214661</td>\n      <td>0.249407</td>\n      <td>0.231498</td>\n      <td>0.318176</td>\n      <td>0.337180</td>\n      <td>0.343603</td>\n      <td>0.351199</td>\n      <td>0.374901</td>\n      <td>0.353494</td>\n      <td>0.396412</td>\n    </tr>\n    <tr>\n      <th>716</th>\n      <td>0.011441</td>\n      <td>0.004713</td>\n      <td>-0.041438</td>\n      <td>0.018533</td>\n      <td>0.005430</td>\n      <td>-0.014529</td>\n      <td>-0.005863</td>\n      <td>-0.098098</td>\n      <td>-0.008055</td>\n      <td>-0.011548</td>\n      <td>...</td>\n      <td>0.299445</td>\n      <td>0.297547</td>\n      <td>0.226758</td>\n      <td>0.404083</td>\n      <td>0.430365</td>\n      <td>0.380261</td>\n      <td>0.401462</td>\n      <td>0.412199</td>\n      <td>0.441784</td>\n      <td>0.415209</td>\n    </tr>\n    <tr>\n      <th>717</th>\n      <td>0.030472</td>\n      <td>0.004713</td>\n      <td>-0.001376</td>\n      <td>0.034183</td>\n      <td>-0.016034</td>\n      <td>0.002141</td>\n      <td>-0.017697</td>\n      <td>-0.051888</td>\n      <td>-0.009368</td>\n      <td>-0.036219</td>\n      <td>...</td>\n      <td>0.385998</td>\n      <td>0.392216</td>\n      <td>0.385719</td>\n      <td>0.522726</td>\n      <td>0.523380</td>\n      <td>0.531310</td>\n      <td>0.561529</td>\n      <td>0.527206</td>\n      <td>0.538442</td>\n      <td>0.534621</td>\n    </tr>\n    <tr>\n      <th>718</th>\n      <td>0.021852</td>\n      <td>0.004713</td>\n      <td>-0.033894</td>\n      <td>0.000751</td>\n      <td>0.044730</td>\n      <td>-0.070975</td>\n      <td>-0.003298</td>\n      <td>-0.035085</td>\n      <td>-0.020736</td>\n      <td>0.016223</td>\n      <td>...</td>\n      <td>0.510391</td>\n      <td>0.536718</td>\n      <td>0.510260</td>\n      <td>0.648294</td>\n      <td>0.554280</td>\n      <td>0.629662</td>\n      <td>0.551755</td>\n      <td>0.647816</td>\n      <td>0.610791</td>\n      <td>0.630213</td>\n    </tr>\n    <tr>\n      <th>719</th>\n      <td>0.114490</td>\n      <td>0.004713</td>\n      <td>-0.063506</td>\n      <td>0.053047</td>\n      <td>0.032656</td>\n      <td>-0.023615</td>\n      <td>0.042644</td>\n      <td>-0.006239</td>\n      <td>-0.028536</td>\n      <td>-0.000599</td>\n      <td>...</td>\n      <td>0.612297</td>\n      <td>0.715656</td>\n      <td>0.608314</td>\n      <td>0.695267</td>\n      <td>0.617968</td>\n      <td>0.705954</td>\n      <td>0.613238</td>\n      <td>0.686861</td>\n      <td>0.733623</td>\n      <td>0.683919</td>\n    </tr>\n  </tbody>\n</table>\n<p>720 rows × 99 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from tqdm import tqdm\n",
    "\n",
    "prediction = pd.DataFrame()\n",
    "\n",
    "for p in tqdm(range(1, 100)):\n",
    "    y = yq_output_df.reset_index().drop('TIMESTAMP', axis=1).drop(range(h1-1))[str(p/100)]\n",
    "    model = MLPRegressor(hidden_layer_sizes=(6,))\n",
    "\n",
    "    trained = model.fit(x[:-24*30], y[:-24*30])\n",
    "    prediction.insert(p-1, str(p/100), trained.predict(x[-24*30:]))\n",
    "\n",
    "prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Postprocessing: Remove quantile crossing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "         0.01      0.02      0.03      0.04      0.05      0.06      0.07  \\\n0    0.167383  0.213278  0.237100  0.302447  0.323161  0.323161  0.347237   \n1    0.234482  0.280707  0.280707  0.353297  0.353297  0.365478  0.380751   \n2    0.239233  0.248735  0.251229  0.316796  0.325106  0.325106  0.337155   \n3    0.164125  0.197023  0.197023  0.214218  0.229559  0.229559  0.252581   \n4    0.055321  0.080528  0.080528  0.134463  0.134463  0.143478  0.143478   \n..        ...       ...       ...       ...       ...       ...       ...   \n715  0.018350  0.018350  0.018350  0.018350  0.018350  0.018350  0.018350   \n716  0.011441  0.011441  0.011441  0.018533  0.018533  0.018533  0.018533   \n717  0.030472  0.030472  0.030472  0.034183  0.034183  0.034183  0.034183   \n718  0.021852  0.021852  0.021852  0.021852  0.044730  0.044730  0.044730   \n719  0.114490  0.114490  0.114490  0.114490  0.114490  0.114490  0.114490   \n\n         0.08      0.09       0.1  ...       0.9      0.91      0.92  \\\n0    0.351798  0.392957  0.392957  ...  0.811886  0.846042  0.846042   \n1    0.394960  0.422626  0.422626  ...  0.828829  0.828829  0.828829   \n2    0.381028  0.395107  0.395107  ...  0.813062  0.813062  0.813062   \n3    0.282923  0.336122  0.336122  ...  0.712231  0.712231  0.719377   \n4    0.143478  0.201728  0.201728  ...  0.587270  0.587270  0.587270   \n..        ...       ...       ...  ...       ...       ...       ...   \n715  0.018350  0.018350  0.020701  ...  0.258827  0.258827  0.258827   \n716  0.018533  0.018533  0.018533  ...  0.308432  0.308432  0.308432   \n717  0.034183  0.034183  0.034183  ...  0.439467  0.439467  0.439467   \n718  0.044730  0.044730  0.044730  ...  0.569276  0.569276  0.569276   \n719  0.114490  0.114490  0.114490  ...  0.655884  0.715656  0.715656   \n\n         0.93      0.94      0.95      0.96      0.97      0.98      0.99  \n0    0.846042  0.852729  0.882909  0.882909  0.882909  0.904169  0.904169  \n1    0.851787  0.911148  0.911148  0.911148  0.911148  0.911148  0.911148  \n2    0.813062  0.862186  0.862186  0.862186  0.862186  0.862186  0.862186  \n3    0.719377  0.781214  0.781214  0.781214  0.781214  0.781214  0.781214  \n4    0.611603  0.656572  0.661266  0.661266  0.661266  0.669207  0.669207  \n..        ...       ...       ...       ...       ...       ...       ...  \n715  0.318176  0.337180  0.343603  0.351199  0.374901  0.374901  0.396412  \n716  0.404083  0.430365  0.430365  0.430365  0.430365  0.441784  0.441784  \n717  0.522726  0.523380  0.531310  0.561529  0.561529  0.561529  0.561529  \n718  0.648294  0.648294  0.648294  0.648294  0.648294  0.648294  0.648294  \n719  0.715656  0.715656  0.715656  0.715656  0.715656  0.733623  0.733623  \n\n[720 rows x 99 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0.01</th>\n      <th>0.02</th>\n      <th>0.03</th>\n      <th>0.04</th>\n      <th>0.05</th>\n      <th>0.06</th>\n      <th>0.07</th>\n      <th>0.08</th>\n      <th>0.09</th>\n      <th>0.1</th>\n      <th>...</th>\n      <th>0.9</th>\n      <th>0.91</th>\n      <th>0.92</th>\n      <th>0.93</th>\n      <th>0.94</th>\n      <th>0.95</th>\n      <th>0.96</th>\n      <th>0.97</th>\n      <th>0.98</th>\n      <th>0.99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.167383</td>\n      <td>0.213278</td>\n      <td>0.237100</td>\n      <td>0.302447</td>\n      <td>0.323161</td>\n      <td>0.323161</td>\n      <td>0.347237</td>\n      <td>0.351798</td>\n      <td>0.392957</td>\n      <td>0.392957</td>\n      <td>...</td>\n      <td>0.811886</td>\n      <td>0.846042</td>\n      <td>0.846042</td>\n      <td>0.846042</td>\n      <td>0.852729</td>\n      <td>0.882909</td>\n      <td>0.882909</td>\n      <td>0.882909</td>\n      <td>0.904169</td>\n      <td>0.904169</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.234482</td>\n      <td>0.280707</td>\n      <td>0.280707</td>\n      <td>0.353297</td>\n      <td>0.353297</td>\n      <td>0.365478</td>\n      <td>0.380751</td>\n      <td>0.394960</td>\n      <td>0.422626</td>\n      <td>0.422626</td>\n      <td>...</td>\n      <td>0.828829</td>\n      <td>0.828829</td>\n      <td>0.828829</td>\n      <td>0.851787</td>\n      <td>0.911148</td>\n      <td>0.911148</td>\n      <td>0.911148</td>\n      <td>0.911148</td>\n      <td>0.911148</td>\n      <td>0.911148</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.239233</td>\n      <td>0.248735</td>\n      <td>0.251229</td>\n      <td>0.316796</td>\n      <td>0.325106</td>\n      <td>0.325106</td>\n      <td>0.337155</td>\n      <td>0.381028</td>\n      <td>0.395107</td>\n      <td>0.395107</td>\n      <td>...</td>\n      <td>0.813062</td>\n      <td>0.813062</td>\n      <td>0.813062</td>\n      <td>0.813062</td>\n      <td>0.862186</td>\n      <td>0.862186</td>\n      <td>0.862186</td>\n      <td>0.862186</td>\n      <td>0.862186</td>\n      <td>0.862186</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.164125</td>\n      <td>0.197023</td>\n      <td>0.197023</td>\n      <td>0.214218</td>\n      <td>0.229559</td>\n      <td>0.229559</td>\n      <td>0.252581</td>\n      <td>0.282923</td>\n      <td>0.336122</td>\n      <td>0.336122</td>\n      <td>...</td>\n      <td>0.712231</td>\n      <td>0.712231</td>\n      <td>0.719377</td>\n      <td>0.719377</td>\n      <td>0.781214</td>\n      <td>0.781214</td>\n      <td>0.781214</td>\n      <td>0.781214</td>\n      <td>0.781214</td>\n      <td>0.781214</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.055321</td>\n      <td>0.080528</td>\n      <td>0.080528</td>\n      <td>0.134463</td>\n      <td>0.134463</td>\n      <td>0.143478</td>\n      <td>0.143478</td>\n      <td>0.143478</td>\n      <td>0.201728</td>\n      <td>0.201728</td>\n      <td>...</td>\n      <td>0.587270</td>\n      <td>0.587270</td>\n      <td>0.587270</td>\n      <td>0.611603</td>\n      <td>0.656572</td>\n      <td>0.661266</td>\n      <td>0.661266</td>\n      <td>0.661266</td>\n      <td>0.669207</td>\n      <td>0.669207</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>715</th>\n      <td>0.018350</td>\n      <td>0.018350</td>\n      <td>0.018350</td>\n      <td>0.018350</td>\n      <td>0.018350</td>\n      <td>0.018350</td>\n      <td>0.018350</td>\n      <td>0.018350</td>\n      <td>0.018350</td>\n      <td>0.020701</td>\n      <td>...</td>\n      <td>0.258827</td>\n      <td>0.258827</td>\n      <td>0.258827</td>\n      <td>0.318176</td>\n      <td>0.337180</td>\n      <td>0.343603</td>\n      <td>0.351199</td>\n      <td>0.374901</td>\n      <td>0.374901</td>\n      <td>0.396412</td>\n    </tr>\n    <tr>\n      <th>716</th>\n      <td>0.011441</td>\n      <td>0.011441</td>\n      <td>0.011441</td>\n      <td>0.018533</td>\n      <td>0.018533</td>\n      <td>0.018533</td>\n      <td>0.018533</td>\n      <td>0.018533</td>\n      <td>0.018533</td>\n      <td>0.018533</td>\n      <td>...</td>\n      <td>0.308432</td>\n      <td>0.308432</td>\n      <td>0.308432</td>\n      <td>0.404083</td>\n      <td>0.430365</td>\n      <td>0.430365</td>\n      <td>0.430365</td>\n      <td>0.430365</td>\n      <td>0.441784</td>\n      <td>0.441784</td>\n    </tr>\n    <tr>\n      <th>717</th>\n      <td>0.030472</td>\n      <td>0.030472</td>\n      <td>0.030472</td>\n      <td>0.034183</td>\n      <td>0.034183</td>\n      <td>0.034183</td>\n      <td>0.034183</td>\n      <td>0.034183</td>\n      <td>0.034183</td>\n      <td>0.034183</td>\n      <td>...</td>\n      <td>0.439467</td>\n      <td>0.439467</td>\n      <td>0.439467</td>\n      <td>0.522726</td>\n      <td>0.523380</td>\n      <td>0.531310</td>\n      <td>0.561529</td>\n      <td>0.561529</td>\n      <td>0.561529</td>\n      <td>0.561529</td>\n    </tr>\n    <tr>\n      <th>718</th>\n      <td>0.021852</td>\n      <td>0.021852</td>\n      <td>0.021852</td>\n      <td>0.021852</td>\n      <td>0.044730</td>\n      <td>0.044730</td>\n      <td>0.044730</td>\n      <td>0.044730</td>\n      <td>0.044730</td>\n      <td>0.044730</td>\n      <td>...</td>\n      <td>0.569276</td>\n      <td>0.569276</td>\n      <td>0.569276</td>\n      <td>0.648294</td>\n      <td>0.648294</td>\n      <td>0.648294</td>\n      <td>0.648294</td>\n      <td>0.648294</td>\n      <td>0.648294</td>\n      <td>0.648294</td>\n    </tr>\n    <tr>\n      <th>719</th>\n      <td>0.114490</td>\n      <td>0.114490</td>\n      <td>0.114490</td>\n      <td>0.114490</td>\n      <td>0.114490</td>\n      <td>0.114490</td>\n      <td>0.114490</td>\n      <td>0.114490</td>\n      <td>0.114490</td>\n      <td>0.114490</td>\n      <td>...</td>\n      <td>0.655884</td>\n      <td>0.715656</td>\n      <td>0.715656</td>\n      <td>0.715656</td>\n      <td>0.715656</td>\n      <td>0.715656</td>\n      <td>0.715656</td>\n      <td>0.715656</td>\n      <td>0.733623</td>\n      <td>0.733623</td>\n    </tr>\n  </tbody>\n</table>\n<p>720 rows × 99 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction['0.01'] = np.maximum(prediction['0.01'], 0)\n",
    "for p in range(2, 100):\n",
    "    prediction[str(p/100)] = np.maximum(prediction[str((p-1)/100)], prediction[str(p/100)])\n",
    "prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate Loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The loss function is the pinnball loss:\n",
    "$$ L(q_a, y) = \\begin{cases}\n",
    "    (1-\\frac{a}{100})(q_a - y), &\\text{if } y < q_a \\\\\n",
    "    \\frac{a}{100}(y-q_a), &\\text{if } y \\geq q_a.\n",
    "\\end{cases} $$\n",
    "\n",
    "The score is then averaged over all target quantiles for all time periods over the forecast horizon and for all zones."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def pinnball_loss(actual, prediction):\n",
    "    actual = actual[...,None]\n",
    "\n",
    "    percentiles = np.empty((actual.shape[0], 99))\n",
    "    for i in range(1, 100):\n",
    "        percentiles[:, i-1] = i\n",
    "    loss = np.where(actual < prediction,\n",
    "                    (1 - percentiles / 100) * (prediction - actual),\n",
    "                    percentiles / 100 * (actual - prediction))\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of task 2 only nearest neighbors: 0.02366\n"
     ]
    }
   ],
   "source": [
    "test_ts = np.squeeze(train_data1['2013-04-01 01:00':].values)\n",
    "loss = np.mean(pinnball_loss(test_ts, yq_output_df['2013-04-01 01:00':]))\n",
    "\n",
    "print(f\"Loss of task {task} only nearest neighbors: {round(loss, 5)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of task 2 with NNQF: 0.04499\n"
     ]
    }
   ],
   "source": [
    "loss = np.mean(pinnball_loss(test_ts, prediction))\n",
    "\n",
    "print(f\"Loss of task {task} with NNQF: {round(loss, 5)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}