\section{Feature Importance}
\label{sec:feature-importance}

One way to determine the importance of a feature for a model is called 
permutation feature importance. Here, the model is trained like usual but during the prediction step, 
we use a modified version of the test data where one feature is randomly permuted over all forecast cases. 
This way, the model cannot use the information of this feature properly 
and will most likely perform worse. The loss on the shuffled dataset is 
then divided by the loss on the regular test set. A value close to \(1\) 
indicates that the feature is not that important because the model doesn't perform 
much worse than before. The higher the quotient, the more important the feature is for the model.
Since our time series heavily depends on the time of day, it makes sense 
not to shuffle the whole feature but only the equivalence classes of each hour, 
i.e., the values at \(1\) AM are shuffled, the values at \(2\) AM are shuffled, etc.

Figure \ref{fig:feature-importance} 
shows the results of the permutation feature importance calculation. 
We can see that the feature importance value for surface solar radiation downwards 
is highest for QRF and NNQF while the total cloud cover predictor is the most important 
for SQF-RNN.

\begin{figure}[h!]
    \input{plots/feature_importance}
    \caption[Feature importance]{Feature importance. 
    The table shows the permutation feature importance quotients. 
    The permutation feature importance quotient is 
    the loss of the model with shuffled feature 
    divided by the loss of the model without shuffled feature. 
    A higher value indicates a more important feature.
    Since only the SQF-RNN model uses the previous points for the prediction, 
    we can only calculate the feature importance of the previous points for this model.}
    \label{fig:feature-importance}
\end{figure}